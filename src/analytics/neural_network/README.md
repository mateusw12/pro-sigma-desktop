# MÃ³dulo de Redes Neurais - MLP

## ğŸ“‹ DescriÃ§Ã£o

MÃ³dulo de anÃ¡lise usando **Multi-Layer Perceptron (MLP)** para problemas de **ClassificaÃ§Ã£o** e **RegressÃ£o**. Implementado com **scikit-learn** e interface grÃ¡fica usando **customtkinter**.

## ğŸ¯ Funcionalidades

### âœ… Tipos de AnÃ¡lise
- **ClassificaÃ§Ã£o**: Problemas com variÃ¡vel alvo categÃ³rica
- **RegressÃ£o**: Problemas com variÃ¡vel alvo contÃ­nua

### âœ… MÃ©todos de ValidaÃ§Ã£o
1. **Holdout**: DivisÃ£o simples em treino/teste
2. **K-Fold Cross-Validation**: ValidaÃ§Ã£o cruzada com k partiÃ§Ãµes

### âœ… Funcionalidades de Treinamento
- **GridSearchCV**: OtimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros
- **MÃºltiplas arquiteturas**: 8 configuraÃ§Ãµes de camadas ocultas
- **FunÃ§Ãµes de ativaÃ§Ã£o**: relu, tanh, logistic, identity
- **Solvers**: adam (otimizador adaptativo), sgd (gradiente estocÃ¡stico)
- **RegularizaÃ§Ã£o**: Ajuste automÃ¡tico de alpha (L2)

### âœ… MÃ©tricas e VisualizaÃ§Ãµes

#### ClassificaÃ§Ã£o
- AcurÃ¡cia
- PrecisÃ£o (Precision)
- Recall
- F1-Score
- ROC-AUC
- Matriz de ConfusÃ£o
- Curva ROC

#### RegressÃ£o
- MSE (Mean Squared Error)
- RMSE (Root Mean Squared Error)
- RÂ² (Coeficiente de DeterminaÃ§Ã£o)
- MÃ©dia e Desvio PadrÃ£o

### âœ… ImportÃ¢ncia de Features
- **Permutation Importance**: Mede o impacto de cada variÃ¡vel nas prediÃ§Ãµes

## ğŸ—ï¸ Arquitetura do CÃ³digo

```
src/analytics/neural_network/
â”œâ”€â”€ __init__.py                  # InicializaÃ§Ã£o do mÃ³dulo
â”œâ”€â”€ neural_network_utils.py      # Backend: treinamento e mÃ©tricas
â””â”€â”€ neural_network_window.py     # Interface grÃ¡fica
```

### Arquivo: `neural_network_utils.py` (493 linhas)

#### Lazy Imports (9 funÃ§Ãµes)
```python
get_sklearn_neural_network()      # MLPClassifier, MLPRegressor
get_sklearn_preprocessing()       # OneHotEncoder, LabelEncoder
get_sklearn_model_selection()    # train_test_split, GridSearchCV, KFold
get_sklearn_metrics()             # accuracy, precision, recall, F1, etc.
get_sklearn_compose()             # ColumnTransformer
get_sklearn_inspection()          # permutation_importance
```

#### FunÃ§Ãµes Principais

**1. `is_categorical_target(y)`**
- Detecta se Y Ã© categÃ³rico (classificaÃ§Ã£o) ou contÃ­nuo (regressÃ£o)
- CritÃ©rio: dtype object ou â‰¤10 valores Ãºnicos

**2. `encode_categorical_columns(df, categorical_cols)`**
- Converte colunas categÃ³ricas usando `LabelEncoder`

**3. `transform_features(X, categorical_cols)`**
- Aplica `OneHotEncoder` em variÃ¡veis categÃ³ricas via `ColumnTransformer`

**4. `calculate_metrics_classification(y_true, y_pred, y_pred_proba)`**
- Calcula todas as mÃ©tricas de classificaÃ§Ã£o
- Retorna: accuracy, precision, recall, F1, confusion_matrix, ROC-AUC, ROC curve

**5. `calculate_metrics_regression(y_true, y_pred)`**
- Calcula mÃ©tricas de regressÃ£o
- Retorna: MSE, RMSE, RÂ², mean, std

**6. `calculate_feature_importance(model, X, y)`**
- Calcula `permutation_importance` com n_repeats=10
- Retorna OrderedDict ordenado por importÃ¢ncia

**7. `train_neural_network_holdout(...)`**
- Treinamento com divisÃ£o Holdout
- ParÃ¢metros:
  - `df`: DataFrame com dados
  - `x_columns`: Colunas X
  - `y_column`: Coluna Y
  - `categorical_cols`: Colunas categÃ³ricas
  - `activation`: FunÃ§Ã£o de ativaÃ§Ã£o
  - `test_size`: ProporÃ§Ã£o de teste (0-1)
  - `max_iter`: MÃ¡ximo de iteraÃ§Ãµes
- GridSearchCV com 24 combinaÃ§Ãµes:
  - `hidden_layer_sizes`: 8 arquiteturas [(5,), (10,), (15,), (5,3), (10,5), (15,10), (10,5,3), (15,10,5)]
  - `solver`: ['adam', 'sgd']
  - `learning_rate`: ['constant', 'adaptive']
  - `alpha`: [0.0001, 0.001, 0.01]
- Retorna: model, is_classification, metrics_train, metrics_test, feature_importance, model_info, predictions

**8. `train_neural_network_kfold(...)`**
- Treinamento com K-Fold Cross-Validation
- Similar ao Holdout mas com mÃºltiplas partiÃ§Ãµes
- Usa `StratifiedKFold` para classificaÃ§Ã£o (preserva proporÃ§Ã£o de classes)
- Retorna mÃ©tricas mÃ©dias e desvio padrÃ£o

### Arquivo: `neural_network_window.py` (730 linhas)

#### Classe: `NeuralNetworkWindow(CTkToplevel)`

**Interface GrÃ¡fica:**
1. **SeleÃ§Ã£o de VariÃ¡veis**
   - Checkboxes para X (mÃºltiplas seleÃ§Ãµes)
   - Radio buttons para Y (seleÃ§Ã£o Ãºnica)
   
2. **ConfiguraÃ§Ãµes**
   - MÃ©todo: Holdout ou K-Fold
   - FunÃ§Ã£o de ativaÃ§Ã£o: relu, tanh, logistic, identity
   - Test Size (%): 10-90% (Holdout)
   - N Folds: 2-10 (K-Fold)
   - Max IteraÃ§Ãµes: 100-2000

3. **Resultados**
   - InformaÃ§Ãµes do Modelo (arquitetura, iteraÃ§Ãµes, loss)
   - Tabela de MÃ©tricas (treino vs teste ou mÃ©dia Â± std)
   - Tabela de ImportÃ¢ncia de Features
   - GrÃ¡fico: Real vs Predito (linha)
   - GrÃ¡fico: ImportÃ¢ncia de Features (barras)
   - GrÃ¡fico: Matriz de ConfusÃ£o (classificaÃ§Ã£o)

## ğŸš€ Como Usar

### 1. Via Interface GrÃ¡fica

1. **Importe dados**: Excel ou CSV na pÃ¡gina inicial
2. **Selecione "Redes Neurais"** no menu de ferramentas
3. **Configure**:
   - Marque variÃ¡veis X
   - Selecione variÃ¡vel Y
   - Escolha mÃ©todo (Holdout ou K-Fold)
   - Ajuste funÃ§Ã£o de ativaÃ§Ã£o
   - Configure parÃ¢metros
4. **Clique em "ğŸš€ Treinar Rede Neural"**
5. **Analise resultados**: mÃ©tricas, grÃ¡ficos, importÃ¢ncia

### 2. Via CÃ³digo Python

```python
from src.analytics.neural_network.neural_network_utils import (
    train_neural_network_holdout,
    train_neural_network_kfold
)
import pandas as pd

# Carrega dados
df = pd.read_excel('dados.xlsx')

# ===== HOLDOUT =====
results_holdout = train_neural_network_holdout(
    df=df,
    x_columns=['Feature1', 'Feature2', 'Feature3'],
    y_column='Target',
    categorical_cols=[],  # Se houver categÃ³ricas: ['Feature1']
    activation='relu',
    test_size=0.3,
    max_iter=500
)

print(f"RÂ² Teste: {results_holdout['metrics_test']['r2']:.4f}")
print(f"Arquitetura: {results_holdout['model_info']['hidden_layers']}")

# ===== K-FOLD =====
results_kfold = train_neural_network_kfold(
    df=df,
    x_columns=['Feature1', 'Feature2', 'Feature3'],
    y_column='Target',
    categorical_cols=[],
    activation='relu',
    n_folds=5,
    max_iter=500
)

print(f"AcurÃ¡cia: {results_kfold['metrics']['accuracy']:.4f} Â± {results_kfold['metrics']['accuracy_std']:.4f}")
```

## ğŸ“Š Exemplo de Output

### Holdout - RegressÃ£o
```python
{
    'model': MLPRegressor(...),
    'is_classification': False,
    'metrics_train': {
        'mse': 0.1234,
        'rmse': 0.3512,
        'r2': 0.9567,
        'mean': 10.5,
        'std': 2.3
    },
    'metrics_test': {
        'mse': 0.1456,
        'rmse': 0.3815,
        'r2': 0.9432,
        'mean': 10.4,
        'std': 2.4
    },
    'feature_importance': {
        'Feature1': 0.234,
        'Feature2': 0.189,
        'Feature3': 0.067
    },
    'model_info': {
        'hidden_layers': (15, 10),
        'n_layers': 2,
        'n_iter': 145,
        'loss': 0.001234,
        'best_params': {
            'hidden_layer_sizes': (15, 10),
            'activation': 'relu',
            'solver': 'adam',
            'learning_rate': 'adaptive',
            'alpha': 0.001
        }
    },
    'y_test': [...],
    'y_pred_test': [...]
}
```

### K-Fold - ClassificaÃ§Ã£o
```python
{
    'model': MLPClassifier(...),
    'is_classification': True,
    'metrics': {
        'accuracy': 0.8756,
        'accuracy_std': 0.0345,
        'precision': 0.8623,
        'precision_std': 0.0412,
        'recall': 0.8901,
        'recall_std': 0.0298,
        'f1_score': 0.8759,
        'f1_score_std': 0.0356,
        'roc_auc': 0.9234,
        'roc_auc_std': 0.0267,
        'confusion_matrix': [[45, 5], [3, 47]]
    },
    'feature_importance': {...},
    'model_info': {
        'n_folds': 5,
        'hidden_layers': (10, 5),
        ...
    }
}
```

## ğŸ”§ HiperparÃ¢metros Otimizados

### GridSearchCV - EspaÃ§o de Busca

| ParÃ¢metro | Valores Testados |
|-----------|------------------|
| `hidden_layer_sizes` | (5,), (10,), (15,), (5,3), (10,5), (15,10), (10,5,3), (15,10,5) |
| `activation` | Definido pelo usuÃ¡rio (relu, tanh, logistic, identity) |
| `solver` | adam, sgd |
| `learning_rate` | constant, adaptive |
| `alpha` | 0.0001, 0.001, 0.01 |

**Total de combinaÃ§Ãµes**: 8 Ã— 1 Ã— 2 Ã— 2 Ã— 3 = **96 modelos** testados

## âš™ï¸ Requisitos

### Bibliotecas Python
```txt
scikit-learn >= 1.0.0
pandas >= 1.3.0
numpy >= 1.21.0
matplotlib >= 3.4.0
customtkinter >= 5.0.0
```

### InstalaÃ§Ã£o
```bash
pip install scikit-learn pandas numpy matplotlib customtkinter
```

## ğŸ§ª Testes

Execute o script de teste:
```bash
python test_neural_network.py
```

Testes incluÃ­dos:
1. âœ… ImportaÃ§Ã£o dos utils
2. âœ… ImportaÃ§Ã£o da janela
3. âœ… DetecÃ§Ã£o de tipo (classificaÃ§Ã£o vs regressÃ£o)
4. âœ… Treinamento Holdout (regressÃ£o)
5. âœ… Treinamento K-Fold (classificaÃ§Ã£o)
6. âœ… ImportÃ¢ncia de features

## ğŸ“ Notas Importantes

### Performance
- **GridSearchCV usa paralelizaÃ§Ã£o**: `n_jobs=-1` (todos os cores disponÃ­veis)
- **Tempo de execuÃ§Ã£o**: 10-60 segundos dependendo do dataset e hiperparÃ¢metros
- **RecomendaÃ§Ã£o**: Use K-Fold apenas com datasets mÃ©dios/grandes (>100 amostras)

### Boas PrÃ¡ticas
1. **NormalizaÃ§Ã£o**: MLP Ã© sensÃ­vel Ã  escala - considere normalizar features numÃ©ricas
2. **VariÃ¡veis categÃ³ricas**: Devem ser identificadas para encoding correto
3. **Max iteraÃ§Ãµes**: Aumente se o modelo nÃ£o convergir (padrÃ£o: 500)
4. **FunÃ§Ã£o de ativaÃ§Ã£o**:
   - `relu`: PadrÃ£o, funciona bem na maioria dos casos
   - `tanh`: Alternativa clÃ¡ssica
   - `logistic`: Para problemas suaves
   - `identity`: Modelo linear (baseline)

### LimitaÃ§Ãµes
- **Dados pequenos**: MLP precisa de amostras suficientes (recomendado: >50 por variÃ¡vel)
- **Overfitting**: Use regularizaÃ§Ã£o (alpha) e validaÃ§Ã£o cruzada
- **Interpretabilidade**: Use feature importance para insights

## ğŸ¯ IntegraÃ§Ã£o

O mÃ³dulo estÃ¡ integrado em:
- âœ… `home_page.py`: Menu "Redes Neurais" (Plano Pro)
- âœ… `license_manager.py`: Feature `'neural_networks'` no Plano Pro
- âœ… `lazy_imports.py`: Imports lazy de sklearn (otimizaÃ§Ã£o de memÃ³ria)

## ğŸ“š ReferÃªncias

- [Scikit-learn MLP](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)
- [GridSearchCV](https://scikit-learn.org/stable/modules/grid_search.html)
- [Permutation Importance](https://scikit-learn.org/stable/modules/permutation_importance.html)

## ğŸ‘¨â€ğŸ’» Autor

**ProSigma Development Team**
- ImplementaÃ§Ã£o: Assistente de IA (GitHub Copilot)
- Data: Maio 2025
- VersÃ£o: 1.0.0

---

**Status**: âœ… **IMPLEMENTADO E FUNCIONAL**
